{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6da845",
   "metadata": {},
   "source": [
    "## 1. Download and label images with Label Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e1acf",
   "metadata": {},
   "source": [
    "**1.1 Install Required Packages**\n",
    "```bash\n",
    "# Core packages\n",
    "pip install label-studio\n",
    "pip install label-studio-converter\n",
    "pip install azure-cognitiveservices-vision-customvision\n",
    "pip install azure-storage-blob\n",
    "pip install coco2customvision\n",
    "pip install pylabel\n",
    "pip install requests\n",
    "pip install python-dotenv\n",
    "```\n",
    "\n",
    "\n",
    "**1.2 Start Label Studio**\n",
    "```bash\n",
    "# Set environment variables\n",
    "\n",
    "# Windows\n",
    "set LOCAL_FILES_SERVING_ENABLED=true\n",
    "set LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=\"C:\\path\\to\\exported_data\"     # If using images that have already been labeled\n",
    "\n",
    "# Git Bash/ Unix-like / Linux\n",
    "export LOCAL_FILES_SERVING_ENABLED=true\n",
    "export LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=\"C:\\path\\to\\exported_data\"     # If using images that have already been labeled\n",
    "\n",
    "# Start Label Studio\n",
    "label-studio\n",
    "```\n",
    "**NOTE:** Make sure you have LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT set to the correct PATH each time your start label-studio!!!\n",
    "\n",
    "**1.3 Set Up Project in Label Studio**\n",
    "1. Open http://localhost:8080\n",
    "2. Create a new project\n",
    "3. Go to Settings → Cloud Storage\n",
    "4. Click Add Source Storage → Local files\n",
    "5. Set Absolute local path to: /path/to/exported_data/images\n",
    "6. Click Add storage\n",
    "7. Then set Target Cloud Storage for annotation output\n",
    "8. Finally go to the `Labeling Interface` tab and add all of your bounding box labels\n",
    "    - Manual Example:\n",
    "```xml\n",
    "<View>\n",
    "  <Image name=\"image\" value=\"$image\"/>\n",
    "  <RectangleLabels name=\"label\" toName=\"image\">\n",
    "    <Label value=\"YourClass1\" background=\"red\"/>\n",
    "    <Label value=\"YourClass2\" background=\"blue\"/>\n",
    "    <!-- Add your actual class names here -->\n",
    "  </RectangleLabels>\n",
    "</View>\n",
    "```\n",
    "\n",
    "**1.4 Import Data**\n",
    "1. In your project, go to Data Manager\n",
    "2. Click Import\n",
    "3. Select the .json file with labels (If using images that have already been labeled)\n",
    "4. Your images and annotations should now be loaded\n",
    "\n",
    "\n",
    "**1.5 Export Annotations**\n",
    "1. In Label Studio, go to your project\n",
    "2. Click Export\n",
    "3. Select COCO format\n",
    "4. Download the exported file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd0a0e",
   "metadata": {},
   "source": [
    "## 2. Send Files to Azure Custom Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4fe2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from decimal import Decimal\n",
    "from pathlib import Path, PurePath\n",
    "from dotenv import load_dotenv\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateEntry, ImageFileCreateBatch, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "ENDPOINT = os.getenv(\"ENDPOINT\")\n",
    "TRAINING_KEY = os.getenv(\"TRAINING_KEY\")\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "COCO_ANNOTATION_FILE = r\"\"\n",
    "IMAGES_DIR = r\"\"\n",
    "MAPPING_FILE = r\"\"\n",
    "\n",
    "# --- AUTHENTICATION ---\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": TRAINING_KEY})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\n",
    "\n",
    "# --- LOAD COCO ANNOTATIONS ---\n",
    "with open(COCO_ANNOTATION_FILE, 'r') as f:\n",
    "    coco = json.load(f)\n",
    "\n",
    "# Build image and annotation lookup\n",
    "images = {img['id']: img for img in coco['images']}\n",
    "annotations_by_image = {}\n",
    "for ann in coco['annotations']:\n",
    "    annotations_by_image.setdefault(ann['image_id'], []).append(ann)\n",
    "\n",
    "# Map COCO categories to Custom Vision tags\n",
    "category_name_to_id = {cat['name']: cat['id'] for cat in coco['categories']}\n",
    "# Get Custom Vision tags (assumes tags already created in project)\n",
    "cv_tags = {tag.name: tag for tag in trainer.get_tags(PROJECT_ID)}\n",
    "\n",
    "# --- MAPPING FUNCTION ---\n",
    "def save_mapping(image_path, cv_image_id, regions_data, mapping_file):\n",
    "    mapping = {}\n",
    "    if os.path.exists(mapping_file):\n",
    "        with open(mapping_file, 'r') as f:\n",
    "            mapping = json.load(f)\n",
    "    mapping[image_path] = {\n",
    "        \"custom_vision_id\": cv_image_id,\n",
    "        \"filename\": os.path.basename(image_path),\n",
    "        \"full_path\": os.path.abspath(image_path),\n",
    "        \"region_count\": len(regions_data),\n",
    "        \"upload_status\": \"success\"\n",
    "    }\n",
    "    with open(mapping_file, 'w') as f:\n",
    "        json.dump(mapping, f, indent=2)\n",
    "\n",
    "# --- MAIN UPLOAD LOOP ---\n",
    "for image_id, image_info in images.items():\n",
    "    img_filename = os.path.basename(image_info['file_name'])\n",
    "    img_path = os.path.join(IMAGES_DIR, img_filename)\n",
    "    assert os.path.exists(img_path), f\"File does not exist: {img_path}\"\n",
    "\n",
    "    width, height = image_info['width'], image_info['height']\n",
    "    regions = []\n",
    "    anns = annotations_by_image.get(image_id, [])\n",
    "    for ann in anns:\n",
    "        cat_id = ann['category_id']\n",
    "        cat_name = next((c['name'] for c in coco['categories'] if c['id'] == cat_id), None)\n",
    "        if cat_name not in cv_tags:\n",
    "            print(f\"Warning: Category '{cat_name}' not found in Custom Vision tags. Skipping annotation.\")\n",
    "            continue\n",
    "        tag_id = cv_tags[cat_name].id\n",
    "        # COCO bbox: [x_min, y_min, width, height]\n",
    "        x, y, w, h = ann['bbox']\n",
    "        x_norm = min(Decimal(x / width), 1)\n",
    "        y_norm = min(Decimal(y / height), 1)\n",
    "        w_norm = min(Decimal(w / width), 1 - x_norm)\n",
    "        h_norm = min(Decimal(h / height), 1 - y_norm)\n",
    "        regions.append(Region(\n",
    "            tag_id=tag_id,\n",
    "            left=float(x_norm),\n",
    "            top=float(y_norm),\n",
    "            width=float(w_norm),\n",
    "            height=float(h_norm)\n",
    "        ))\n",
    "\n",
    "    with open(img_path, \"rb\") as image_contents:\n",
    "        image_and_annotations = [\n",
    "            ImageFileCreateEntry(name=img_filename, contents=image_contents.read(), regions=regions)\n",
    "        ]\n",
    "\n",
    "    upload_result = trainer.create_images_from_files(\n",
    "        PROJECT_ID,\n",
    "        ImageFileCreateBatch(images=image_and_annotations)\n",
    "    )\n",
    "\n",
    "    if not upload_result.is_batch_successful:\n",
    "        print(f\"Image upload failed for {img_path}.\")\n",
    "        for image in upload_result.images:\n",
    "            print(\"Image status:\", image.status)\n",
    "            print(\"Regions:\", regions)\n",
    "    else:\n",
    "        cv_image_id = upload_result.images[0].image.id\n",
    "        save_mapping(img_path, cv_image_id, regions, MAPPING_FILE)\n",
    "\n",
    "print(\"Upload complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9dec9a",
   "metadata": {},
   "source": [
    "## 3. Train and evaluate your model in Azure Custom Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1111885d",
   "metadata": {},
   "source": [
    "## 4. Add new images to local training data if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc354805",
   "metadata": {},
   "source": [
    "## 5. Use your current Azure Model to predict the bounding boxes on your new trianing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0693cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests, json, uuid\n",
    "from PIL import Image\n",
    "\n",
    "# ROOT is the path to your new training images\n",
    "ROOT = Path(r\"\")\n",
    "HEADERS = {\n",
    "    \"Prediction-Key\": os.getenv(\"PREDICTION_KEY\"),\n",
    "    \"Content-Type\": \"application/octet-stream\"\n",
    "}\n",
    "ENDPOINT = os.getenv(\"ENDPOINT\")\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "ITERATION_NAME = os.getenv(\"ITERATION_NAME\")\n",
    "CONFIDENCE_THRESHOLD = 0.82\n",
    "\n",
    "EXPORT_DIR = Path(\"azure_cv_annotations.json\")\n",
    "EXPORT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "EXPORT_DIR = Path(\"azure_cv_annotations.json\")\n",
    "EXPORT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "for img_path in ROOT.glob(\"*.png\"):\n",
    "    # Load image and get dimensions\n",
    "    with Image.open(img_path) as img:\n",
    "        width, height = img.size\n",
    "\n",
    "    # Send image to Custom Vision API\n",
    "    data = img_path.read_bytes()\n",
    "    resp = requests.post(\n",
    "        f\"{ENDPOINT}/customvision/v3.0/Prediction/{PROJECT_ID}/detect/iterations/{ITERATION_NAME}/image\",\n",
    "        headers=HEADERS,\n",
    "        data=data\n",
    "    )\n",
    "    preds = resp.json()[\"predictions\"]\n",
    "\n",
    "    img_path_uri = \"file:\" + img_path.as_posix().replace(\" \", \"%20\")\n",
    "\n",
    "    # Build JSON asset\n",
    "    json_asset = {\n",
    "        \"asset\": {\n",
    "            \"format\": \"png\",\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"name\": img_path.name,\n",
    "            \"path\": img_path_uri,\n",
    "            \"size\": {\"width\": width, \"height\": height},\n",
    "            \"state\": 2,      # tagged\n",
    "            \"type\": 1        # image\n",
    "        },\n",
    "        \"regions\": [{\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"tags\": [p[\"tagName\"]],\n",
    "            \"boundingBox\": {\n",
    "                \"left\": p[\"boundingBox\"][\"left\"],\n",
    "                \"top\": p[\"boundingBox\"][\"top\"],\n",
    "                \"width\": p[\"boundingBox\"][\"width\"],\n",
    "                \"height\": p[\"boundingBox\"][\"height\"]\n",
    "            }\n",
    "        } for p in preds if p[\"probability\"] > CONFIDENCE_THRESHOLD],\n",
    "    }\n",
    "\n",
    "    # Save JSON to file\n",
    "    output_file = EXPORT_DIR / f\"{img_path.stem}-asset.json\"\n",
    "    output_file.write_text(json.dumps(json_asset, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1ca2c8",
   "metadata": {},
   "source": [
    "**Convert the Azure label files to a format Label Studio can read**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff366fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from urllib.parse import unquote\n",
    "from PIL import Image\n",
    "\n",
    "def get_image_size(path: Path) -> tuple[int, int]:\n",
    "    with Image.open(path) as img:\n",
    "        return img.width, img.height\n",
    "\n",
    "\n",
    "def convert_json_directory_to_labelstudio(\n",
    "    json_dir: str,\n",
    "    output_file: str,\n",
    "    image_root_url=\"/data/local-files/?d=images\",\n",
    "    copy_images_to: str | None = None\n",
    "):\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files\")\n",
    "\n",
    "    if not json_files:\n",
    "        return\n",
    "\n",
    "    label_studio_tasks, all_tags = [], set()\n",
    "    processed_count = 0\n",
    "\n",
    "    for jf in json_files:\n",
    "        with open(jf, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        asset, regions = data.get(\"asset\", {}), data.get(\"regions\", [])\n",
    "        if not regions:\n",
    "            continue\n",
    "\n",
    "        image_name = asset.get(\"name\", \"\")\n",
    "        image_path = Path(unquote(asset.get(\"path\", \"\").replace(\"file:\", \"\")))\n",
    "\n",
    "        if not image_name or not image_path.exists():\n",
    "            continue\n",
    "\n",
    "        # Copy image if requested\n",
    "        if copy_images_to:\n",
    "            dest = Path(copy_images_to) / image_name\n",
    "            dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "            if not dest.exists():\n",
    "                import shutil\n",
    "                shutil.copy2(image_path, dest)\n",
    "        else:\n",
    "            dest = image_path  # original location\n",
    "\n",
    "        # Determine dimensions once per image\n",
    "        orig_w, orig_h = get_image_size(dest)\n",
    "\n",
    "        # Build task\n",
    "        task = {\n",
    "            \"data\": {\"image\": f\"{image_root_url}/{image_name}\"},\n",
    "            \"annotations\": [{\"result\": []}]\n",
    "        }\n",
    "\n",
    "        for region in regions:\n",
    "            bbox, tags = region.get(\"boundingBox\", {}), region.get(\"tags\", [])\n",
    "            if not bbox or not tags:\n",
    "                continue\n",
    "\n",
    "            x_pct, y_pct = bbox.get(\"left\", 0) * 100, bbox.get(\"top\", 0) * 100\n",
    "            w_pct, h_pct = bbox.get(\"width\", 0) * 100, bbox.get(\"height\", 0) * 100\n",
    "\n",
    "            all_tags.update(tags)\n",
    "            for tag in tags:\n",
    "                task[\"annotations\"][0][\"result\"].append({\n",
    "                    \"id\": region.get(\"id\") or f\"region_{len(task['annotations'][0]['result'])}\",\n",
    "                    \"value\": {\n",
    "                        \"x\": x_pct,\n",
    "                        \"y\": y_pct,\n",
    "                        \"width\": w_pct,\n",
    "                        \"height\": h_pct,\n",
    "                        \"rectanglelabels\": [tag],\n",
    "                        \"original_width\": orig_w,\n",
    "                        \"original_height\": orig_h,\n",
    "                        \"rotation\": 0\n",
    "                    },\n",
    "                    \"from_name\": \"label\",\n",
    "                    \"to_name\": \"image\",\n",
    "                    \"type\": \"rectanglelabels\",\n",
    "                    \"origin\": \"manual\"\n",
    "                })\n",
    "\n",
    "        label_studio_tasks.append(task)\n",
    "        processed_count += 1\n",
    "\n",
    "    os.makedirs(Path(output_file).parent, exist_ok=True)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(label_studio_tasks, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Converted {processed_count} files ➜ {output_file}\")\n",
    "    print(f\"Labels found: {sorted(all_tags)}\")\n",
    "\n",
    "    # Generate XML config\n",
    "    cfg_path = Path(output_file).with_suffix(\"_config.xml\")\n",
    "    xml = \"<View>\\n  <Image name=\\\"image\\\" value=\\\"$image\\\"/>\\n  <RectangleLabels name=\\\"label\\\" toName=\\\"image\\\">\\n\"\n",
    "    xml += \"\\n\".join([f'    <Label value=\"{t}\" background=\"#{hash(t)%0xFFFFFF:06x}\"/>' for t in sorted(all_tags)])\n",
    "    xml += \"\\n  </RectangleLabels>\\n</View>\"\n",
    "    cfg_path.write_text(xml, encoding=\"utf-8\")\n",
    "    print(f\"Wrote interface config ➜ {cfg_path}\")\n",
    "\n",
    "    return label_studio_tasks, sorted(all_tags)\n",
    "\n",
    "def batch_convert_with_image_copy(json_dir, output_dir=\"label_studio_data\", images_subdir=\"images\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    images_dir = os.path.join(output_dir, images_subdir)\n",
    "    \n",
    "    tasks, tags = convert_json_directory_to_labelstudio(\n",
    "        json_dir=json_dir,\n",
    "        output_file=os.path.join(output_dir, \"label_studio_tasks.json\"),\n",
    "        image_root_url=f\"/data/local-files/?d={images_subdir}\",  # CORRECT: /data/local-files/?d=images\n",
    "        copy_images_to=images_dir\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n=== SETUP INSTRUCTIONS ===\")\n",
    "    print(f\"1. Set environment variables:\")\n",
    "    print(f\"   export LOCAL_FILES_SERVING_ENABLED=true\")\n",
    "    print(f\"   export LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=\\\"{os.path.abspath(output_dir)}\\\"\")\n",
    "    print(f\"2. Start Label Studio\")\n",
    "    print(f\"3. Create project with XML config from: {os.path.join(output_dir, 'label_studio_tasks_config.xml')}\")\n",
    "    print(f\"4. Set local storage path to: {os.path.abspath(images_dir)}\")\n",
    "    print(f\"5. Import: {os.path.join(output_dir, 'label_studio_tasks.json')}\")\n",
    "    \n",
    "    return tasks, tags\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    json_directory = r\"\"\n",
    "    \n",
    "    batch_convert_with_image_copy(\n",
    "        json_dir=json_directory,\n",
    "        output_dir=\"\",\n",
    "        images_subdir=\"images\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50627969",
   "metadata": {},
   "source": [
    "## *Back to step one*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1850921b",
   "metadata": {},
   "source": [
    "#### Extra Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c291d7ca",
   "metadata": {},
   "source": [
    "#### 1. Loading all images from Azure Custom Vision with labels to be checked in Label Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateEntry, Region\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import json\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ENDPOINT = os.getenv(\"ENDPOINT\")\n",
    "TRAINING_KEY = os.getenv(\"TRAINING_KEY\")\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "ITERATION_ID = None # or None for latest\n",
    "IMAGES_PER_PAGE = 256\n",
    "\n",
    "credentials = ApiKeyCredentials(in_headers={\"Training-key\": TRAINING_KEY})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, credentials)\n",
    "\n",
    "def export_annotations_only():\n",
    "    # Get all images with pagination\n",
    "    all_images = []\n",
    "    skip = 0\n",
    "    take = 256\n",
    "    \n",
    "    while True:\n",
    "        print(f\"Fetching images {skip} to {skip + take}...\")\n",
    "        images_batch = trainer.get_images(PROJECT_ID, skip=skip, take=take)\n",
    "        \n",
    "        if hasattr(images_batch, 'images'):\n",
    "            batch_list = images_batch.images  \n",
    "        else:\n",
    "            batch_list = images_batch\n",
    "        \n",
    "        if not batch_list:\n",
    "            break\n",
    "            \n",
    "        all_images.extend(batch_list)\n",
    "        skip += take\n",
    "        \n",
    "        if len(batch_list) < take:\n",
    "            break\n",
    "    \n",
    "    print(f\"Found {len(all_images)} total images\")\n",
    "    \n",
    "    # Create export data\n",
    "    export_data = {\n",
    "        \"project_info\": {\n",
    "            \"total_images\": len(all_images),\n",
    "            \"images_with_annotations\": 0\n",
    "        },\n",
    "        \"categories\": [],\n",
    "        \"images\": []\n",
    "    }\n",
    "    \n",
    "    # Get project tags\n",
    "    tags = trainer.get_tags(PROJECT_ID)\n",
    "    for tag in tags:\n",
    "        export_data[\"categories\"].append({\n",
    "            \"id\": tag.id,\n",
    "            \"name\": tag.name\n",
    "        })\n",
    "    \n",
    "    # Process images\n",
    "    for img_idx, image in enumerate(all_images):\n",
    "        image_data = {\n",
    "            \"id\": image.id,\n",
    "            \"index\": img_idx,\n",
    "            \"width\": image.width,\n",
    "            \"height\": image.height,\n",
    "            \"original_uri\": image.original_image_uri,\n",
    "            \"regions\": []\n",
    "        }\n",
    "        \n",
    "        if hasattr(image, 'regions') and image.regions:\n",
    "            export_data[\"project_info\"][\"images_with_annotations\"] += 1\n",
    "            \n",
    "            for region in image.regions:\n",
    "                region_data = {\n",
    "                    \"tag_name\": region.tag_name if hasattr(region, 'tag_name') else str(region.tag_id),\n",
    "                    \"left\": region.left,\n",
    "                    \"top\": region.top,\n",
    "                    \"width\": region.width,\n",
    "                    \"height\": region.height\n",
    "                }\n",
    "                image_data[\"regions\"].append(region_data)\n",
    "        \n",
    "        export_data[\"images\"].append(image_data)\n",
    "    \n",
    "    # Save annotation data\n",
    "    os.makedirs('exported_data', exist_ok=True)\n",
    "    with open('exported_data/custom_vision_export.json', 'w') as f:\n",
    "        json.dump(export_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Exported annotation data for {len(all_images)} images\")\n",
    "    print(f\"Images with annotations: {export_data['project_info']['images_with_annotations']}\")\n",
    "    print(f\"Categories: {len(export_data['categories'])}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    export_annotations_only()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c9340",
   "metadata": {},
   "source": [
    "**Convert to Label Studio readable format with mapping to images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "# Load Azure Custom Vision export\n",
    "with open('custom_vision_export.json', 'r') as f:\n",
    "    azure_data = json.load(f)\n",
    "\n",
    "# Load mapping file\n",
    "with open('mapping.json', 'r') as f:\n",
    "    mapping = json.load(f)\n",
    "\n",
    "# Build a reverse mapping: custom_vision_id -> mapping info\n",
    "id_to_mapping = {v['custom_vision_id']: v for v in mapping.values()}\n",
    "\n",
    "# Set your Label Studio image prefix (adjust as needed)\n",
    "LABEL_STUDIO_IMAGE_PREFIX = '/data/local-files/?d=images/'\n",
    "\n",
    "# Set your desired output image size (Label Studio expects the original size)\n",
    "# If you have the true original size, use it. Otherwise, use the width/height from Azure.\n",
    "def get_original_size(image):\n",
    "    return image['width'], image['height']\n",
    "\n",
    "label_studio_tasks = []\n",
    "task_id = 1\n",
    "annotation_id = 1\n",
    "\n",
    "for image in azure_data['images']:\n",
    "    custom_vision_id = image['id']\n",
    "    mapping_info = id_to_mapping.get(custom_vision_id)\n",
    "    if not mapping_info:\n",
    "        print(f\"Warning: No mapping found for image id {custom_vision_id}\")\n",
    "        continue\n",
    "\n",
    "    filename = mapping_info['filename']\n",
    "    # Compose the Label Studio image path\n",
    "    ls_image_path = LABEL_STUDIO_IMAGE_PREFIX + filename\n",
    "\n",
    "    width, height = get_original_size(image)\n",
    "\n",
    "    # Build Label Studio annotation results\n",
    "    results = []\n",
    "    for region in image.get('regions', []):\n",
    "        # Azure gives normalized coordinates (0-1), Label Studio expects percent (0-100)\n",
    "        x = region['left'] * 100\n",
    "        y = region['top'] * 100\n",
    "        w = region['width'] * 100\n",
    "        h = region['height'] * 100\n",
    "\n",
    "        result = {\n",
    "            \"original_width\": width,\n",
    "            \"original_height\": height,\n",
    "            \"image_rotation\": 0,\n",
    "            \"value\": {\n",
    "                \"x\": x,\n",
    "                \"y\": y,\n",
    "                \"width\": w,\n",
    "                \"height\": h,\n",
    "                \"rotation\": 0,\n",
    "                \"rectanglelabels\": [region['tag_name']]\n",
    "            },\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"from_name\": \"label\",\n",
    "            \"to_name\": \"image\",\n",
    "            \"type\": \"rectanglelabels\",\n",
    "            \"origin\": \"manual\"\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    # Build the annotation object\n",
    "    annotation = {\n",
    "        \"id\": annotation_id,\n",
    "        \"completed_by\": 1,\n",
    "        \"result\": results,\n",
    "        \"was_cancelled\": False,\n",
    "        \"ground_truth\": True,\n",
    "        \"created_at\": \"\",\n",
    "        \"updated_at\": \"\",\n",
    "        \"draft_created_at\": None,\n",
    "        \"lead_time\": None,\n",
    "        \"prediction\": {},\n",
    "        \"result_count\": len(results),\n",
    "        \"unique_id\": str(uuid.uuid4()),\n",
    "        \"import_id\": None,\n",
    "        \"last_action\": None,\n",
    "        \"bulk_created\": False,\n",
    "        \"task\": task_id,\n",
    "        \"project\": 4,\n",
    "        \"updated_by\": 1,\n",
    "        \"parent_prediction\": None,\n",
    "        \"parent_annotation\": None,\n",
    "        \"last_created_by\": None\n",
    "    }\n",
    "\n",
    "    # Build the task object\n",
    "    task = {\n",
    "        \"id\": task_id,\n",
    "        \"annotations\": [annotation],\n",
    "        \"file_upload\": \"\",\n",
    "        \"drafts\": [],\n",
    "        \"predictions\": [],\n",
    "        \"data\": {\n",
    "            \"image\": ls_image_path\n",
    "        },\n",
    "        \"meta\": {},\n",
    "        \"created_at\": \"\",\n",
    "        \"updated_at\": \"\",\n",
    "        \"inner_id\": task_id,\n",
    "        \"total_annotations\": 1,\n",
    "        \"cancelled_annotations\": 0,\n",
    "        \"total_predictions\": 0,\n",
    "        \"comment_count\": 0,\n",
    "        \"unresolved_comment_count\": 0,\n",
    "        \"last_comment_updated_at\": None,\n",
    "        \"project\": 4,\n",
    "        \"updated_by\": 1,\n",
    "        \"comment_authors\": []\n",
    "    }\n",
    "\n",
    "    label_studio_tasks.append(task)\n",
    "    task_id += 1\n",
    "    annotation_id += 1\n",
    "\n",
    "# Write to output file\n",
    "with open('label_studio_tasks.json', 'w') as f:\n",
    "    json.dump(label_studio_tasks, f, indent=2)\n",
    "\n",
    "print(f\"Exported {len(label_studio_tasks)} tasks to label_studio_tasks.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conversion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
